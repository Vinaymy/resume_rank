{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts Microsoft docx documents to txt documents\n",
    "import docx2txt\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "# For Keywrods Frequency Coutns\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Keywords Repository\n",
    "# Python file with multiple lists of segredated keywords\n",
    "import keywords as keywords_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_spec_text = docx2txt.process('web developer.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions used in the Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngrams_creator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    \n",
    "    ngrams_creator()\n",
    "    \n",
    "    Inputs:\n",
    "        1. ngrams_text_source - String\n",
    "        2. num_grams - Number of N-grams to be generated\n",
    "            - Bigrams\n",
    "            - Trigrams\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def ngrams_creator(ngrams_text_source, num_grams):\n",
    "    # Returns a list of n-grams strings\n",
    "    n_grams = ngrams(word_tokenize(ngrams_text_source), num_grams)\n",
    "    n_grams = [' '.join(grams) for grams in n_grams]\n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data to list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    job_spec_cleaner():\n",
    "    \n",
    "    Inputs\n",
    "        1. Text data from Job Spec File (String) \n",
    "\n",
    "    Outputs\n",
    "        1. job_spec_sentences\n",
    "            1. List\n",
    "            2. Cleaned sentences in job spec file\n",
    "\"\"\"\n",
    "\n",
    "def job_spec_cleaner(job_spec_text):\n",
    "    \n",
    "    # To store cleaned sentences\n",
    "    job_spec_sentences = []\n",
    "    \n",
    "    # Controller for removing punctuation\n",
    "    remove_punctuation = True\n",
    "    \n",
    "    # Creating translator for translate function\n",
    "    # Used to replace punctuation with empty space\n",
    "    if remove_punctuation == True:\n",
    "        punctuation_to_remove = \"!$%&\\'()*,-./:;<=>?[\\\\]^_`{|}~â€¢\"\n",
    "        punctuation_translator = str.maketrans(\n",
    "            punctuation_to_remove, ' '*len(punctuation_to_remove))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # Convert Job Spec File to individual lines\n",
    "    # Clean them up\n",
    "    for line in job_spec_text.splitlines():\n",
    "        if line != \"\":\n",
    "            line = line.replace('\\t', '')  # Replace Tabs with empty string\n",
    "            line = line.strip()  # Remove extra whitespace\n",
    "            line = line.lower()  # Convert text to lowercase\n",
    "            line = line.split(' ') # Convert string to list\n",
    "            line = [word for word in line if word] # Remove empty list elements\n",
    "            if len(line) > 1:\n",
    "                line_str = ' '.join(line)\n",
    "                if remove_punctuation == True:\n",
    "                    # Swap punctuation with single empty space\n",
    "                    line_str = line_str.translate(punctuation_translator)\n",
    "                    job_spec_sentences.append(line_str)\n",
    "                else:\n",
    "                    job_spec_sentences.append(line_str)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return job_spec_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    find_keywords()\n",
    "    \n",
    "    Searchs for:\n",
    "        1. Technical Keywords\n",
    "        2. Education degree\n",
    "        3. Education field of study\n",
    "    \n",
    "    Inputs\n",
    "        1. Cleaned sentences from Job Spec File (List)\n",
    "        \n",
    "    Output\n",
    "        1. matched_keywords (List)\n",
    "        2. List of all keywords found\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def find_keywords(job_spec_sentences):\n",
    "    \n",
    "    # List of keywords found\n",
    "    matched_keywords = []\n",
    "    \n",
    "    # Controllers for searching N-grams\n",
    "    search_unigrams = True\n",
    "    search_ngrams = True\n",
    "    \n",
    "    keywords_to_search = keywords_file.database_keywords + \\\n",
    "        keywords_file.education_degree + keywords_file.education_field_study \\\n",
    "        + keywords_file.machine_learning_keywords + keywords_file.programming_keywords\n",
    "\n",
    "    # Removing duplicates\n",
    "    keywords_to_search = list(set(keywords_to_search))\n",
    "    \n",
    "    # Match Unigrams\n",
    "    if search_unigrams == True:\n",
    "        text_to_search = ' '.join(job_spec_sentences)\n",
    "        text_to_search = text_to_search.split(' ')\n",
    "        # Removing empty strings\n",
    "        text_to_search = [word for word in text_to_search if word]\n",
    "        for word in text_to_search:\n",
    "            if word in keywords_to_search:\n",
    "                matched_keywords.append(word)\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    # Match Bigrams and Trigrams\n",
    "    if search_ngrams == True:\n",
    "        text_to_search = ' '.join(text_to_search)\n",
    "        text_bigrams = ngrams_creator(text_to_search, 2)\n",
    "        text_trigrams = ngrams_creator(text_to_search, 3)\n",
    "        text_combined_ngrams = text_bigrams + text_trigrams\n",
    "        for word in text_combined_ngrams:\n",
    "            if word in keywords_to_search:\n",
    "                matched_keywords.append(word)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    return matched_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segregate Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    sort_keywords()\n",
    "    \n",
    "    Sorting extracted keywords\n",
    "        1. Required technical skills\n",
    "        2. Optional technical skills\n",
    "        3. Education Degree\n",
    "        4. Education Major/Field\n",
    "        \n",
    "    Input\n",
    "        1. job_spec_keywords_found - Extracted keywords list\n",
    "        2. job_spec_sentences - Cleaned Sentences\n",
    "        \n",
    "    Output\n",
    "        1. data_for_auto_job_spec_form - Dictionary of sorted keywords\n",
    "            1. required_keywords\n",
    "            2. optional_keywords\n",
    "            3. other_keywords\n",
    "            4. education_degree_keywords\n",
    "            5. education_field_keywords\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def sort_keywords(job_spec_keywords_found, job_spec_sentences):\n",
    "    \n",
    "    # Selectors are used to find out if a sentence has:\n",
    "    # Optional Keywords \n",
    "    # Required Keywords\n",
    "    # Education Keywords\n",
    "    required_keywords_selectors = keywords_file.required_keywords_selectors\n",
    "    optional_words_selectors = keywords_file.optional_keywords_selectors\n",
    "    \n",
    "    required_keywords_sentences = []\n",
    "    optional_keywords_sentences = []\n",
    "    education_related_sentences = []\n",
    "    \n",
    "    for sentence in job_spec_sentences:\n",
    "        individual_sentence_unigrams = sentence.split(' ')\n",
    "        individual_sentence_bigrams = ngrams_creator(sentence, 2)\n",
    "        individual_sentence_trigrams = ngrams_creator(sentence, 3)\n",
    "        individual_sentence = individual_sentence_unigrams + individual_sentence_bigrams + individual_sentence_trigrams\n",
    "        \n",
    "        for word in individual_sentence:\n",
    "            if word in required_keywords_selectors:\n",
    "                required_keywords_sentences.append(sentence)\n",
    "                continue\n",
    "            elif word in optional_words_selectors:\n",
    "                optional_keywords_sentences.append(sentence)\n",
    "                continue\n",
    "            elif word in keywords_file.education_degree or word in keywords_file.education_field_study:\n",
    "                education_related_sentences.append(sentence)\n",
    "                continue\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    # Check for matched keywords in segregated sentences\n",
    "    required_keywords_sentences_merged = ' '.join(required_keywords_sentences)\n",
    "    required_keywords_sentences_unigrams = required_keywords_sentences_merged.split()\n",
    "    required_keywords_sentences_bigrams = ngrams_creator(required_keywords_sentences_merged, 2)\n",
    "    required_keywords_sentences_trigrams = ngrams_creator(required_keywords_sentences_merged, 3)\n",
    "    required_keywords_sentences_ngrams = required_keywords_sentences_unigrams + required_keywords_sentences_bigrams + required_keywords_sentences_trigrams\n",
    "    \n",
    "    optional_keywords_sentences_merged = ' '.join(optional_keywords_sentences)\n",
    "    optional_keywords_unigrams = optional_keywords_sentences_merged.split()\n",
    "    optional_keywords_bigrams = ngrams_creator(optional_keywords_sentences_merged, 2)\n",
    "    optional_keywords_trigrams = ngrams_creator(optional_keywords_sentences_merged, 3)\n",
    "    optinal_keywords_sentences_ngrams = optional_keywords_unigrams + optional_keywords_bigrams + optional_keywords_trigrams\n",
    "    \n",
    "    \n",
    "    sorted_required_keywords = []\n",
    "    sorted_optional_keywords = []\n",
    "    sorted_other_keywords = []\n",
    "    \n",
    "    # Sorting Technical skills keywords\n",
    "    for word in job_spec_keywords_found:\n",
    "        if word in required_keywords_sentences_ngrams:\n",
    "            sorted_required_keywords.append(word)\n",
    "            continue\n",
    "        elif word in optinal_keywords_sentences_ngrams:\n",
    "            sorted_optional_keywords.append(word)\n",
    "            continue\n",
    "        else:\n",
    "            sorted_other_keywords.append(word)\n",
    "            \n",
    "            \n",
    "            \n",
    "    education_related_sentences_merged = ' '.join(education_related_sentences)\n",
    "    education_related_sentences_unigrams = education_related_sentences_merged.split()\n",
    "    education_related_sentences_bigrams = ngrams_creator(education_related_sentences_merged, 2)\n",
    "    education_related_sentences_trigrams = ngrams_creator(education_related_sentences_merged, 3)\n",
    "    education_related_sentences_ngrams = education_related_sentences_unigrams + education_related_sentences_bigrams + education_related_sentences_trigrams\n",
    "\n",
    "    \n",
    "    # Sorting education related keywords\n",
    "    sorted_education_degree_keywords = []\n",
    "    sorted_education_field_keywords = []\n",
    "    \n",
    "    for word in job_spec_keywords_found:\n",
    "        if word in keywords_file.education_phd:\n",
    "            sorted_education_degree_keywords = sorted_education_degree_keywords + \\\n",
    "                keywords_file.education_phd\n",
    "        if word in keywords_file.education_masters:\n",
    "            sorted_education_degree_keywords = sorted_education_degree_keywords + \\\n",
    "                keywords_file.education_masters\n",
    "        if word in keywords_file.education_bachelors:\n",
    "            sorted_education_degree_keywords = sorted_education_degree_keywords + \\\n",
    "                keywords_file.education_bachelors\n",
    "        if word in keywords_file.education_freshers:\n",
    "            sorted_education_degree_keywords = sorted_education_degree_keywords + \\\n",
    "                keywords_file.education_freshers\n",
    "        if word in keywords_file.education_field_study:\n",
    "            sorted_education_field_keywords.append(word)\n",
    "            \n",
    "    \n",
    "    sorted_required_keywords = list(set(sorted_required_keywords))\n",
    "    sorted_optional_keywords = list(set(sorted_optional_keywords))\n",
    "    sorted_other_keywords = list(set(sorted_other_keywords))\n",
    "    sorted_education_degree_keywords = list(set(sorted_education_degree_keywords))\n",
    "    sorted_education_field_keywords = list(set(sorted_education_field_keywords))\n",
    "    \n",
    "    data_for_auto_job_spec_form = {\n",
    "        \"required_keywords\": sorted_required_keywords,\n",
    "        \"optional_keywords\": sorted_optional_keywords,\n",
    "        \"other_keywords\": sorted_other_keywords,\n",
    "        \"education_degree_keywords\": sorted_education_degree_keywords,\n",
    "        \"education_field_keywords\": sorted_education_field_keywords,\n",
    "    }\n",
    "    \n",
    "    return data_for_auto_job_spec_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch overall years of professional experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    get_years_of_experience()\n",
    "    \n",
    "    Looking for the minimum years of experience requirement\n",
    "    \n",
    "    1. Input\n",
    "        1. Job Specification sentences (List)\n",
    "    \n",
    "    2. Output\n",
    "        1. exp_min_nos_years (Integer)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_years_of_experience(job_spec_sentences):\n",
    "    # If experience not found\n",
    "    # Then we show it as 0\n",
    "    exp_min_nos_years = 0\n",
    "    \n",
    "    # List of possible 'Years of experience sentences'\n",
    "    # Trying to get the overall one\n",
    "    possible_experience_sentences = []\n",
    "    \n",
    "    # Extracting sentences that might be experience related\n",
    "    for sentence in job_spec_sentences:\n",
    "        # Controllers\n",
    "        word_year_years_found = False\n",
    "        word_experience_found = False\n",
    "        \n",
    "        # Tokenize sentences\n",
    "        tokenized_sentence = sentence.split()\n",
    "        \n",
    "        # For each word in tokenized sentence\n",
    "        for word in tokenized_sentence:\n",
    "            if word == 'year' or word == 'years':\n",
    "                word_year_years_found = True\n",
    "            elif word == 'experience':\n",
    "                word_experience_found = True\n",
    "            else:\n",
    "                continue # Carry on with the next word\n",
    "        \n",
    "        # If both controllers set to True\n",
    "        # Add the sentence to possible_experience_sentences\n",
    "        if word_year_years_found == True and word_experience_found == True:\n",
    "            possible_experience_sentences.append(sentence)\n",
    "        else:\n",
    "            continue # Carry on with the next sentence\n",
    "            \n",
    "        # Check if list is empty\n",
    "        if len(possible_experience_sentences) == 0:\n",
    "            exp_min_nos_years = 0\n",
    "        else:\n",
    "            # Get the first item in the list\n",
    "            # Usually, the first mention of experience is the overall one\n",
    "            experience_sentence = possible_experience_sentences[0]\n",
    "            extracted_years_raw = re.search(r'\\d{1,2}\\W?(to|\\W)?.?\\d{1,2}.?(year|years)', experience_sentence).group() # Returns a list\n",
    "            if len(extracted_years_raw) == 0: # At present, only looking for digits. Ignoring eg: 'two years of experice'\n",
    "                    exp_min_nos_years = 0\n",
    "            else:\n",
    "                years_regex_str = extracted_years_raw[0]\n",
    "                years_lstripped = years_regex_str.lstrip()\n",
    "                years_splitted = years_lstripped.split(' ')\n",
    "                years_first_number = years_splitted[0] # For weirdos like 4.2 or 2.8\n",
    "                years_final_list = re.findall(r'\\d{1,2}', years_first_number)\n",
    "                exp_min_nos_years = int(years_final_list[0])\n",
    "\n",
    "    return exp_min_nos_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_spec_data(job_spec_content):\n",
    "    \n",
    "    # Get data cleaned\n",
    "    # Get list of sentences\n",
    "    job_spec_sentences = job_spec_cleaner(job_spec_content)\n",
    "    \n",
    "    # Find all keywords\n",
    "    job_spec_keywords_found = find_keywords(job_spec_sentences)\n",
    "    \n",
    "    # Sort keywords\n",
    "    data_for_auto_job_spec_form = sort_keywords(job_spec_keywords_found, job_spec_sentences)\n",
    "    \n",
    "    # Find years of experience\n",
    "    min_years_experience = get_years_of_experience(job_spec_sentences)\n",
    "    \n",
    "    data_for_auto_job_spec_form['experience_min_nos_years'] = min_years_experience\n",
    "\n",
    "    print('\\n------------\\n Job Spec Sentences')\n",
    "    print(job_spec_sentences)\n",
    "    \n",
    "    print('\\n\\nAll keywords\\n')\n",
    "    print(job_spec_keywords_found)\n",
    "    \n",
    "    print('\\n\\nConsolidated Data\\n')\n",
    "    print(data_for_auto_job_spec_form)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------\n",
      " Job Spec Sentences\n",
      "['job description', 'job title  web developer', 'essential duties and responsibilities ', '  a forward thinker who is passionate about innovative technologies ', '  keep up with rapid innovations in the the industry and consistently brings new ideas to the team', '  work in rapid prototype and agile development environment', '  contribute critical parts of the platform and deliver to production ', 'minimum qualifications ', 'masters   bachelors in computer science or similar field', '2 to 4 years of experience  freshers with proven work are also encouraged to apply ', 'knowledge and skills ', 'experience with c  c++  c#  cakephp  firebase  jquery  node js  objective c', 'good understanding of databases such as postgresql  ms access  sql server  oracledb', 'must have knowledge of codeignitor  cakephp  drupal  wordpress etc', '1of 1']\n",
      "\n",
      "\n",
      "All keywords\n",
      "\n",
      "['masters', 'bachelors', 'freshers', 'c', 'c++', 'c#', 'cakephp', 'firebase', 'jquery', 'c', 'postgresql', 'oracledb', 'codeignitor', 'cakephp', 'drupal', 'wordpress', 'computer science', 'node js', 'objective c', 'ms access', 'sql server']\n",
      "\n",
      "\n",
      "Consolidated Data\n",
      "\n",
      "{'required_keywords': ['drupal', 'ms access', 'oracledb', 'codeignitor', 'cakephp', 'postgresql', 'sql server', 'wordpress'], 'optional_keywords': ['c++', 'jquery', 'firebase', 'c', 'c#', 'node js', 'objective c'], 'other_keywords': ['bachelors', 'masters', 'freshers', 'computer science'], 'education_degree_keywords': ['msc', 'm sc', 'masters', 'm tech', 'mca', 'bsc', 'master', 'b tech', 'bachelor', 'mtech', 'bachelors', 'b c a', 'b sc', 'bca', 'master s', 'm c a', 'btech'], 'education_field_keywords': ['computer science'], 'experience_min_nos_years': 2}\n"
     ]
    }
   ],
   "source": [
    "get_job_spec_data(job_spec_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-sorting",
   "language": "python",
   "name": "resume-sorting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
